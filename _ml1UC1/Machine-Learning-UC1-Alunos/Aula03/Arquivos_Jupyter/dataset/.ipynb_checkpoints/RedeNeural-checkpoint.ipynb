{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81803b43-971f-44a7-8f35-5c3e14eec945",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\murilo.dores\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\murilo.dores\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\murilo.dores\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\murilo.dores\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\murilo.dores\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package rslp to\n",
      "[nltk_data]     C:\\Users\\murilo.dores\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping stemmers\\rslp.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import regex\n",
    "import unicodedata\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Baixa o modelo de tokenização para português e outros compomentes do NLTK\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('omw-1.4')  # Suporte multilíngue\n",
    "nltk.download('wordnet')   # WordNet principal\n",
    "nltk.download('rslp')\n",
    "\n",
    "#def download_nltk_resource(resource):\n",
    "#    try:\n",
    "#        nltk.data.find(resource)\n",
    "#    except LookupError:\n",
    "#        nltk.download(resource.split('/')[-1])\n",
    "#\n",
    "# Baixa os recursos necessários\n",
    "# download_nltk_resource('tokenizers/punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c194b388-1f37-472e-8703-c140d8e18566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto original: \n",
      "\t['Olá, tudo bem? Este é um texto de Exemplo!', 'Eu amo programação em Python e Machine Learning.', 'Texto com MUITAS PONTUAÇÕES... e alguns STOP WORDS!', 'Outro exemplo: A corrida de dados é essencial em ML!!!']\n",
      "\n",
      "Texto limpo   : \n",
      "\t['olá tudo bem texto exemplo', 'amo programação python machine learning', 'texto muitas pontuações alguns stop words', 'outro exemplo corrida dados essencial ml']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "# Lista de textos de exemplo\n",
    "##\n",
    "#texto = \"Bom dia! Como você está?\"\n",
    "#texto = \"Olá, tudo bem? Meu nome é Zé das Coves. Gosto de programação!\"\n",
    "texto = [\n",
    "    \"Olá, tudo bem? Este é um texto de Exemplo!\",\n",
    "    \"Eu amo programação em Python e Machine Learning.\",\n",
    "    \"Texto com MUITAS PONTUAÇÕES... e alguns STOP WORDS!\",\n",
    "    \"Outro exemplo: A corrida de dados é essencial em ML!!!\"\n",
    "]\n",
    "\n",
    "\n",
    "# 1) Definir stopwords (ex.: português, mas ajuste conforme sua necessidade)\n",
    "# \"de\", \"a\", \"o\", \"e\", ...\n",
    "stopwords_pt = set(stopwords.words('portuguese'))  \n",
    "\n",
    "# 2) Função de limpeza e tokenização\n",
    "def preprocess_text(text):\n",
    "    # a) Colocar tudo em minúsculo\n",
    "    text = text.lower()\n",
    "    \n",
    "    # b) Remover pontuações e caracteres especiais (regex)\n",
    "    #text = re.sub(r'[^a-z0-9\\s]', '', text)\n",
    "    #text = re.sub(r'[.,!?;:()\\[\\]{}\\'\"\\-_]', '', text)\n",
    "    text = regex.sub(r'\\p{P}+', '', text)\n",
    "\n",
    "    # c) Tokenizar de forma simples (split por espaço)\n",
    "    #tokens = text.split()\n",
    "    tokens = word_tokenize(text, language='portuguese')    \n",
    "    \n",
    "    # d) Remover stopwords\n",
    "    tokens = [t for t in tokens if t not in stopwords_pt]\n",
    "    \n",
    "    # e) Reunir tokens novamente, se quisermos gerar um \"texto limpo\"\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# 3) Limpar cada texto na lista\n",
    "texto_limpo = [preprocess_text(txt) for txt in texto]\n",
    "\n",
    "\n",
    "print (f\"Texto original: \\n\\t{texto}\\n\")\n",
    "print (f\"Texto limpo   : \\n\\t{texto_limpo}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd6f51b0-f12b-4cab-aa36-cb05272c201e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stemming    : run\n",
      "Lematização : running\n",
      "\n",
      "Stemming    : correndo\n",
      "Lematização : correndo\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer, WordNetLemmatizer, RSLPStemmer\n",
    "import spacy\n",
    "\n",
    "##\n",
    "# Inglês\n",
    "##\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "print(\"\\nStemming    :\", stemmer.stem(\"running\"))\n",
    "print(\"Lematização :\", lemmatizer.lemmatize(\"running\"))\n",
    "\n",
    "print(\"\\nStemming    :\", stemmer.stem(\"correndo\"))\n",
    "print(\"Lematização :\", lemmatizer.lemmatize(\"correndo\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0984ad3d-1411-48c9-8f87-fbfd07dabb75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Palavras    : ['correr', 'correndo', 'corrida', 'cão', 'cães']\n",
      "Stemming PT : ['corr', 'corr', 'corr', 'cão', 'cão'] \n",
      "\n",
      "Palavra: Eu \t → Lemma: eu\n",
      "Palavra: estava \t → Lemma: estar\n",
      "Palavra: correndo \t → Lemma: correr\n",
      "Palavra: com \t → Lemma: com\n",
      "Palavra: meus \t → Lemma: meu\n",
      "Palavra: cães \t → Lemma: cão\n",
      "Palavra: na \t → Lemma: em o\n",
      "Palavra: praia \t → Lemma: praia\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "# Portugues - Stemming\n",
    "##\n",
    "stemmer_pt = RSLPStemmer()\n",
    "\n",
    "palavras = [\"correr\", \"correndo\", \"corrida\", \"cão\", \"cães\"]\n",
    "print(f\"\\nPalavras    : {palavras}\")\n",
    "\n",
    "palavras_stemmed = [stemmer_pt.stem(p) for p in palavras]\n",
    "print(f\"Stemming PT : {palavras_stemmed} \\n\")\n",
    "\n",
    "\n",
    "##\n",
    "# Portugues - Lematização \n",
    "##\n",
    "\n",
    "# Carrega o modelo em português\n",
    "nlp = spacy.load(\"pt_core_news_sm\")  \n",
    "\n",
    "frase = \"Eu estava correndo com meus cães na praia\"\n",
    "doc = nlp(frase)\n",
    "for token in doc:\n",
    "    print(f\"Palavra: {token.text} \\t → Lemma: {token.lemma_}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7723be5-701d-4039-b35f-4ae3b841ec43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original             : olá tudo bem texto exemplo\n",
      "Lematizada           : olá tudo bem texto exemplo\n",
      "Lematizada s/acento  : ola tudo bem texto exemplo\n",
      "\n",
      "Original             : amo programação python machine learning\n",
      "Lematizada           : amo programação python Machine learning\n",
      "Lematizada s/acento  : amo programacao python Machine learning\n",
      "\n",
      "Original             : texto muitas pontuações alguns stop words\n",
      "Lematizada           : texto muito pontuação algum stop word\n",
      "Lematizada s/acento  : texto muito pontuacao algum stop word\n",
      "\n",
      "Original             : outro exemplo corrida dados essencial ml\n",
      "Lematizada           : outro exemplo corrida dar essencial ml\n",
      "Lematizada s/acento  : outro exemplo corrida dar essencial ml\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "# Portugues\n",
    "##\n",
    "\n",
    "# Carrega o modelo em português\n",
    "nlp = spacy.load(\"pt_core_news_sm\")  \n",
    "\n",
    "def lemmatizar_frases(lista_frases):\n",
    "    frases_lematizadas = []\n",
    "    \n",
    "    for frase in lista_frases:\n",
    "        doc = nlp(frase)\n",
    "        # Lematiza cada token e junta novamente em uma string\n",
    "        frase_lematizada = \" \".join([token.lemma_ for token in doc])\n",
    "        frases_lematizadas.append(frase_lematizada)\n",
    "    \n",
    "    return frases_lematizadas\n",
    "\n",
    "def remover_acentos(texto):\n",
    "    # Normaliza o texto (decompõe os caracteres acentuados em caracteres simples + acento)\n",
    "    texto_normalizado = unicodedata.normalize('NFKD', texto)\n",
    "\n",
    "    # Remove os caracteres de acentuação (como ~, ´, `, ^, etc.)\n",
    "    texto_sem_acentos = ''.join(c for c in texto_normalizado if not unicodedata.combining(c))\n",
    "    \n",
    "    return texto_sem_acentos\n",
    "\n",
    "\n",
    "# Aplica a lematização\n",
    "texto_lematizado = lemmatizar_frases(texto_limpo)\n",
    "\n",
    "# Removendo os acentos\n",
    "texto_lematizado_sem_acento=[]\n",
    "for linha in texto_lematizado:\n",
    "    linha_sem_acento=remover_acentos(linha)\n",
    "    texto_lematizado_sem_acento.append(linha_sem_acento)\n",
    "\n",
    "# Mostra o resultado\n",
    "for original, lematizada, lematizada_sem_acento in zip(texto_limpo, texto_lematizado,  texto_lematizado_sem_acento):\n",
    "    print(f\"Original             : {original}\")\n",
    "    print(f\"Lematizada           : {lematizada}\")\n",
    "    print(f\"Lematizada s/acento  : {lematizada_sem_acento}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6db12f5-87a4-4c21-af93-f694a4626c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Vocabulário: \n",
      "\n",
      "['algum' 'amo' 'bem' 'corrida' 'dar' 'essencial' 'exemplo' 'learning'\n",
      " 'machine' 'ml' 'muito' 'ola' 'outro' 'pontuacao' 'programacao' 'python'\n",
      " 'stop' 'texto' 'tudo' 'word']\n",
      "\n",
      "\n",
      "Matriz BOW:\n",
      "\n",
      " [[0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 1 0]\n",
      " [0 1 0 0 0 0 0 1 1 0 0 0 0 0 1 1 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0 1]\n",
      " [0 0 0 1 1 1 1 0 0 1 0 0 1 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# 4) Vetorizar com CountVectorizer (Bag-of-Words)\n",
    "vectorizer = CountVectorizer()\n",
    "bow_matrix = vectorizer.fit_transform(texto_lematizado_sem_acento)\n",
    "\n",
    "print(f\"\\n\\nVocabulário: \\n\\n{vectorizer.get_feature_names_out()}\\n\")\n",
    "print(f\"\\nMatriz BOW:\\n\\n {bow_matrix.toarray()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f83929f9-ac93-4bd6-b98d-136529568d5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algum</th>\n",
       "      <th>amo</th>\n",
       "      <th>bem</th>\n",
       "      <th>corrida</th>\n",
       "      <th>dar</th>\n",
       "      <th>essencial</th>\n",
       "      <th>exemplo</th>\n",
       "      <th>learning</th>\n",
       "      <th>machine</th>\n",
       "      <th>ml</th>\n",
       "      <th>muito</th>\n",
       "      <th>ola</th>\n",
       "      <th>outro</th>\n",
       "      <th>pontuacao</th>\n",
       "      <th>programacao</th>\n",
       "      <th>python</th>\n",
       "      <th>stop</th>\n",
       "      <th>texto</th>\n",
       "      <th>tudo</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   algum  amo  bem  corrida  dar  essencial  exemplo  learning  machine  ml  \\\n",
       "0      0    0    1        0    0          0        1         0        0   0   \n",
       "1      0    1    0        0    0          0        0         1        1   0   \n",
       "2      1    0    0        0    0          0        0         0        0   0   \n",
       "3      0    0    0        1    1          1        1         0        0   1   \n",
       "\n",
       "   muito  ola  outro  pontuacao  programacao  python  stop  texto  tudo  word  \n",
       "0      0    1      0          0            0       0     0      1     1     0  \n",
       "1      0    0      0          0            1       1     0      0     0     0  \n",
       "2      1    0      0          1            0       0     1      1     0     1  \n",
       "3      0    0      1          0            0       0     0      0     0     0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5) Converter para DataFrame, apenas para visualização\n",
    "bow_df = pd.DataFrame(bow_matrix.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "bow_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "742ee929-24ee-4ffc-a645-7dbf5996b005",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_df.to_csv('dataset_bow_matrizx-2025.06.30.csv', index=False)\n",
    "bow_df.to_csv('dataset_bow_matrizx-2025.06.30.csv.gzip', compression='gzip', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85d22d3b-1381-49bf-9e61-32fbce8594b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Textos originais:\n",
      "\t1: Olá, tudo bem? Este é um texto de Exemplo!\n",
      "\t2: Eu amo programação em Python e Machine Learning.\n",
      "\t3: Texto com MUITAS PONTUAÇÕES... e alguns STOP WORDS!\n",
      "\t4: Outro exemplo: A corrida de dados é essencial em ML!!!\n",
      "\n",
      "Textos pós-limpeza:\n",
      "\t1: ola tudo bem texto exemplo\n",
      "\t2: amo programacao python Machine learning\n",
      "\t3: texto muito pontuacao algum stop word\n",
      "\t4: outro exemplo corrida dar essencial ml\n",
      "\n",
      "Matriz Bag-of-Words:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algum</th>\n",
       "      <th>amo</th>\n",
       "      <th>bem</th>\n",
       "      <th>corrida</th>\n",
       "      <th>dar</th>\n",
       "      <th>essencial</th>\n",
       "      <th>exemplo</th>\n",
       "      <th>learning</th>\n",
       "      <th>machine</th>\n",
       "      <th>ml</th>\n",
       "      <th>muito</th>\n",
       "      <th>ola</th>\n",
       "      <th>outro</th>\n",
       "      <th>pontuacao</th>\n",
       "      <th>programacao</th>\n",
       "      <th>python</th>\n",
       "      <th>stop</th>\n",
       "      <th>texto</th>\n",
       "      <th>tudo</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   algum  amo  bem  corrida  dar  essencial  exemplo  learning  machine  ml  \\\n",
       "0      0    0    1        0    0          0        1         0        0   0   \n",
       "1      0    1    0        0    0          0        0         1        1   0   \n",
       "2      1    0    0        0    0          0        0         0        0   0   \n",
       "3      0    0    0        1    1          1        1         0        0   1   \n",
       "\n",
       "   muito  ola  outro  pontuacao  programacao  python  stop  texto  tudo  word  \n",
       "0      0    1      0          0            0       0     0      1     1     0  \n",
       "1      0    0      0          0            1       1     0      0     0     0  \n",
       "2      1    0      0          1            0       0     1      1     0     1  \n",
       "3      0    0      1          0            0       0     0      0     0     0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print (f\"Texto original: \\n\\t{texto}\\n\")\n",
    "print(\"Textos originais:\")\n",
    "for i, t in enumerate(texto):\n",
    "    print(f\"\\t{i+1}: {t}\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nTextos pós-limpeza:\")\n",
    "for i, ct in enumerate(texto_lematizado_sem_acento):\n",
    "    print(f\"\\t{i+1}: {ct}\")\n",
    "\n",
    "print(\"\\nMatriz Bag-of-Words:\")\n",
    "bow_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eaa01fa-9967-4e38-8cd9-f240a07e9a0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python ML (venv)",
   "language": "python",
   "name": "machine_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
